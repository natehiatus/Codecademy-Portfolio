{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Rentals Analysis\n",
    "***\n",
    "This analysis was conducted as a project from Codecademy’s Data Engineer Career\n",
    "Path. The course provided the source data and the following prompt to start the project:\n",
    "\n",
    "> A bike rental company has asked you to create a database to help their analysts understand the \n",
    "effects of weather on bike rentals. You’ve been given a year of bike rental data from the company \n",
    "and you’ll source weather data from the government. You’ll need to clean and validate both data \n",
    "sets, design a relational PostgreSQL database to store the data, and develop views for the \n",
    "database to assist the analytics team.\n",
    "\n",
    "## (1.) Prepare Data and Environment (VSCode)\n",
    "<img src=\"images/project_start_folder.png\" width=\"600\">\n",
    "<br>\n",
    "<br>\n",
    "Setup Jupyter Notebook in VSCode with a virtual environment (.venv) for the project <br>\n",
    "<img src=\"images/vscode_folder.png\" width=\"300\">\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## (2.) Import, Inspect, Clean, and Export files (Python)\n",
    "\n",
    "### Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip Duration</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Stop Time</th>\n",
       "      <th>Start Station ID</th>\n",
       "      <th>Start Station Name</th>\n",
       "      <th>Start Station Latitude</th>\n",
       "      <th>Start Station Longitude</th>\n",
       "      <th>End Station ID</th>\n",
       "      <th>End Station Name</th>\n",
       "      <th>End Station Latitude</th>\n",
       "      <th>End Station Longitude</th>\n",
       "      <th>Bike ID</th>\n",
       "      <th>User Type</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>361</td>\n",
       "      <td>2016-02-01 00:31:18</td>\n",
       "      <td>2016-02-01 00:37:19</td>\n",
       "      <td>3202</td>\n",
       "      <td>Newport PATH</td>\n",
       "      <td>40.727224</td>\n",
       "      <td>-74.033759</td>\n",
       "      <td>3203</td>\n",
       "      <td>Hamilton Park</td>\n",
       "      <td>40.727596</td>\n",
       "      <td>-74.044247</td>\n",
       "      <td>24393</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297</td>\n",
       "      <td>2016-02-01 01:55:05</td>\n",
       "      <td>2016-02-01 02:00:02</td>\n",
       "      <td>3195</td>\n",
       "      <td>Sip Ave</td>\n",
       "      <td>40.730743</td>\n",
       "      <td>-74.063784</td>\n",
       "      <td>3194</td>\n",
       "      <td>McGinley Square</td>\n",
       "      <td>40.725340</td>\n",
       "      <td>-74.067622</td>\n",
       "      <td>24394</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1155</td>\n",
       "      <td>2016-02-01 02:40:05</td>\n",
       "      <td>2016-02-01 02:59:20</td>\n",
       "      <td>3183</td>\n",
       "      <td>Exchange Place</td>\n",
       "      <td>40.716247</td>\n",
       "      <td>-74.033459</td>\n",
       "      <td>3210</td>\n",
       "      <td>Pershing Field</td>\n",
       "      <td>40.742677</td>\n",
       "      <td>-74.051789</td>\n",
       "      <td>24676</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1769</td>\n",
       "      <td>2016-02-01 05:11:28</td>\n",
       "      <td>2016-02-01 05:40:58</td>\n",
       "      <td>3214</td>\n",
       "      <td>Essex Light Rail</td>\n",
       "      <td>40.712774</td>\n",
       "      <td>-74.036486</td>\n",
       "      <td>3203</td>\n",
       "      <td>Hamilton Park</td>\n",
       "      <td>40.727596</td>\n",
       "      <td>-74.044247</td>\n",
       "      <td>24700</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>935</td>\n",
       "      <td>2016-02-01 05:48:24</td>\n",
       "      <td>2016-02-01 06:03:59</td>\n",
       "      <td>3203</td>\n",
       "      <td>Hamilton Park</td>\n",
       "      <td>40.727596</td>\n",
       "      <td>-74.044247</td>\n",
       "      <td>3214</td>\n",
       "      <td>Essex Light Rail</td>\n",
       "      <td>40.712774</td>\n",
       "      <td>-74.036486</td>\n",
       "      <td>24639</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trip Duration           Start Time            Stop Time  Start Station ID  \\\n",
       "0            361  2016-02-01 00:31:18  2016-02-01 00:37:19              3202   \n",
       "1            297  2016-02-01 01:55:05  2016-02-01 02:00:02              3195   \n",
       "2           1155  2016-02-01 02:40:05  2016-02-01 02:59:20              3183   \n",
       "3           1769  2016-02-01 05:11:28  2016-02-01 05:40:58              3214   \n",
       "4            935  2016-02-01 05:48:24  2016-02-01 06:03:59              3203   \n",
       "\n",
       "  Start Station Name  Start Station Latitude  Start Station Longitude  \\\n",
       "0       Newport PATH               40.727224               -74.033759   \n",
       "1            Sip Ave               40.730743               -74.063784   \n",
       "2     Exchange Place               40.716247               -74.033459   \n",
       "3   Essex Light Rail               40.712774               -74.036486   \n",
       "4      Hamilton Park               40.727596               -74.044247   \n",
       "\n",
       "   End Station ID  End Station Name  End Station Latitude  \\\n",
       "0            3203     Hamilton Park             40.727596   \n",
       "1            3194   McGinley Square             40.725340   \n",
       "2            3210    Pershing Field             40.742677   \n",
       "3            3203     Hamilton Park             40.727596   \n",
       "4            3214  Essex Light Rail             40.712774   \n",
       "\n",
       "   End Station Longitude  Bike ID   User Type  Birth Year  Gender  \n",
       "0             -74.044247    24393  Subscriber      1975.0       1  \n",
       "1             -74.067622    24394  Subscriber      1985.0       2  \n",
       "2             -74.051789    24676  Subscriber      1976.0       1  \n",
       "3             -74.044247    24700  Subscriber      1974.0       2  \n",
       "4             -74.036486    24639  Subscriber      1974.0       2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# use glob to collect csv's and concat them to a single csv\n",
    "files = glob.glob(\"project_starter_kit/data/JC-*-citibike-tripdata.csv\")\n",
    "df_list = []\n",
    "for filename in files:\n",
    "    data = pd.read_csv(filename)\n",
    "    df_list.append(data)\n",
    "\n",
    "bikedata = pd.concat(df_list)\n",
    "\n",
    "weather = pd.read_csv(\"project_starter_kit/data/newark_airport_2016.csv\")\n",
    "bikedata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(bikedata): 247584\n",
      "number of bikes: 566\n",
      "min(start_time): 2016-01-01 00:02:52\n",
      "max(start_time): 2016-12-31 23:44:50\n",
      "youngest rider: 16.0 years old\n",
      "oldest rider: 116.0 years old\n",
      "avg trip duration: 14.76 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip Duration</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Stop Time</th>\n",
       "      <th>Start Station ID</th>\n",
       "      <th>Start Station Name</th>\n",
       "      <th>Start Station Latitude</th>\n",
       "      <th>Start Station Longitude</th>\n",
       "      <th>End Station ID</th>\n",
       "      <th>End Station Name</th>\n",
       "      <th>End Station Latitude</th>\n",
       "      <th>End Station Longitude</th>\n",
       "      <th>Bike ID</th>\n",
       "      <th>User Type</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>361</td>\n",
       "      <td>2016-02-01 00:31:18</td>\n",
       "      <td>2016-02-01 00:37:19</td>\n",
       "      <td>3202</td>\n",
       "      <td>Newport PATH</td>\n",
       "      <td>40.727224</td>\n",
       "      <td>-74.033759</td>\n",
       "      <td>3203</td>\n",
       "      <td>Hamilton Park</td>\n",
       "      <td>40.727596</td>\n",
       "      <td>-74.044247</td>\n",
       "      <td>24393</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297</td>\n",
       "      <td>2016-02-01 01:55:05</td>\n",
       "      <td>2016-02-01 02:00:02</td>\n",
       "      <td>3195</td>\n",
       "      <td>Sip Ave</td>\n",
       "      <td>40.730743</td>\n",
       "      <td>-74.063784</td>\n",
       "      <td>3194</td>\n",
       "      <td>McGinley Square</td>\n",
       "      <td>40.725340</td>\n",
       "      <td>-74.067622</td>\n",
       "      <td>24394</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1155</td>\n",
       "      <td>2016-02-01 02:40:05</td>\n",
       "      <td>2016-02-01 02:59:20</td>\n",
       "      <td>3183</td>\n",
       "      <td>Exchange Place</td>\n",
       "      <td>40.716247</td>\n",
       "      <td>-74.033459</td>\n",
       "      <td>3210</td>\n",
       "      <td>Pershing Field</td>\n",
       "      <td>40.742677</td>\n",
       "      <td>-74.051789</td>\n",
       "      <td>24676</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1769</td>\n",
       "      <td>2016-02-01 05:11:28</td>\n",
       "      <td>2016-02-01 05:40:58</td>\n",
       "      <td>3214</td>\n",
       "      <td>Essex Light Rail</td>\n",
       "      <td>40.712774</td>\n",
       "      <td>-74.036486</td>\n",
       "      <td>3203</td>\n",
       "      <td>Hamilton Park</td>\n",
       "      <td>40.727596</td>\n",
       "      <td>-74.044247</td>\n",
       "      <td>24700</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>935</td>\n",
       "      <td>2016-02-01 05:48:24</td>\n",
       "      <td>2016-02-01 06:03:59</td>\n",
       "      <td>3203</td>\n",
       "      <td>Hamilton Park</td>\n",
       "      <td>40.727596</td>\n",
       "      <td>-74.044247</td>\n",
       "      <td>3214</td>\n",
       "      <td>Essex Light Rail</td>\n",
       "      <td>40.712774</td>\n",
       "      <td>-74.036486</td>\n",
       "      <td>24639</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trip Duration           Start Time            Stop Time  Start Station ID Start Station Name  Start Station Latitude  Start Station Longitude  End Station ID  End Station Name  End Station Latitude  End Station Longitude  Bike ID   User Type  Birth Year  Gender\n",
       "0            361  2016-02-01 00:31:18  2016-02-01 00:37:19              3202       Newport PATH               40.727224               -74.033759            3203     Hamilton Park             40.727596             -74.044247    24393  Subscriber      1975.0       1\n",
       "1            297  2016-02-01 01:55:05  2016-02-01 02:00:02              3195            Sip Ave               40.730743               -74.063784            3194   McGinley Square             40.725340             -74.067622    24394  Subscriber      1985.0       2\n",
       "2           1155  2016-02-01 02:40:05  2016-02-01 02:59:20              3183     Exchange Place               40.716247               -74.033459            3210    Pershing Field             40.742677             -74.051789    24676  Subscriber      1976.0       1\n",
       "3           1769  2016-02-01 05:11:28  2016-02-01 05:40:58              3214   Essex Light Rail               40.712774               -74.036486            3203     Hamilton Park             40.727596             -74.044247    24700  Subscriber      1974.0       2\n",
       "4            935  2016-02-01 05:48:24  2016-02-01 06:03:59              3203      Hamilton Park               40.727596               -74.044247            3214  Essex Light Rail             40.712774             -74.036486    24639  Subscriber      1974.0       2"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 1000) \n",
    "pd.set_option('display.max_columns',504)\n",
    "pd.set_option('display.width',1000)\n",
    "\n",
    "# print(bikedata.head(10))\n",
    "# print(weather.head(10))\n",
    "\n",
    "\n",
    "#bikedata -----------------------------------\n",
    "print(\"len(bikedata): \" + str(len(bikedata)))\n",
    "bike_dup = bikedata.duplicated()\n",
    "#print(bike_dup.value_counts())\n",
    "\n",
    "print(\"number of bikes: \" + str(len(bikedata['Bike ID'].unique())))\n",
    "\n",
    "print(\"min(start_time): \" + str(bikedata['Start Time'].min()))\n",
    "print(\"max(start_time): \" + str(bikedata['Start Time'].max()))\n",
    "print(\"youngest rider: \" + str(2016 - bikedata['Birth Year'].max()) + \" years old\")\n",
    "print(\"oldest rider: \" + str(2016 - bikedata['Birth Year'].min()) + \" years old\")\n",
    "print(\"avg trip duration: \" + str(round(bikedata['Trip Duration'].mean() / 60, 2)) + \" minutes\")\n",
    "\n",
    "\n",
    "# The oldest person known to have lived in New Jersey in 2016 was Adele Dunlap, \n",
    "# who at the time was the oldest living person in the United States. She was born on December 12, 1902, \n",
    "# and lived in Hunterdon County, New Jersey. In 2016, she turned 114 years old. She passed away on \n",
    "# February 5, 2017, at the age of 114 years and 51 days.\n",
    "\n",
    "\n",
    "#too_old = bikedata[bikedata.birth_year < 1902]\n",
    "\n",
    "\n",
    "# station_names = bikedata['Start Station Name'].unique()\n",
    "# station_names\n",
    "\n",
    "# 9’s in a field (e.g.9999) indicate missing data or data that has not been received.\n",
    "\n",
    "bikedata.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust column names\n",
    "bikedata.columns = bikedata.columns.str.lower().str.replace(' ','_')\n",
    "weather.columns = weather.columns.str.lower()\n",
    "\n",
    "#get rid of riders that are too old\n",
    "bikedata = bikedata[bikedata.birth_year >= 1902]\n",
    "\n",
    "#edit gender column: use strings 'M', 'F', and 'U' instead of int 1, 2, and 0\n",
    "def gender(num):\n",
    "    if num == 0:\n",
    "        return 'U'\n",
    "    elif num == 1:\n",
    "        return 'M'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "bikedata.gender = bikedata.gender.astype(int).apply(gender)\n",
    "\n",
    "# change birth year to int \n",
    "bikedata.birth_year = bikedata.birth_year.astype(int)\n",
    "\n",
    "#create stations df \n",
    "bikedata = bikedata.rename(columns = {'start_station_latitude': 'start_latitude', \n",
    "                                      'start_station_longitude': 'start_longitude', \n",
    "                                      'end_station_latitude': 'end_latitude', \n",
    "                                      'end_station_longitude': 'end_longitude'})\n",
    "\n",
    "start_stations = bikedata[['start_station_id', 'start_station_name', 'start_latitude','start_longitude']].drop_duplicates() # create start_stations df\n",
    "\n",
    "start_stations.columns = start_stations.columns.str.replace('start_', '') # modify column names\n",
    "\n",
    "end_stations = bikedata[['end_station_id', 'end_station_name', 'end_latitude','end_longitude']].drop_duplicates() # create end_stations df\n",
    "end_stations.columns = end_stations.columns.str.replace('end_', '')\n",
    "\n",
    "stations = pd.concat([start_stations, end_stations]).drop_duplicates().reset_index(drop=True) # use start_stations and end_stations to create stations df, making sure all stations in the data are included.\n",
    "stations.columns = stations.columns.str.replace('station_', '') # modify column names\n",
    "\n",
    "# create trip_data df \n",
    "trip_data = bikedata[['bike_id', 'start_station_id', 'start_time', 'end_station_id', 'stop_time', 'trip_duration', 'user_type', 'birth_year', 'gender']]\n",
    "\n",
    "# clean weather table \n",
    "weather = weather.drop(columns = ['pgtm', 'tsun'])\n",
    "weather.columns.str.lower()\n",
    "weather = weather.rename(columns = {'awnd': 'awnd_mph', 'snwd': 'snw_dpth'})\n",
    "weather = weather.drop(columns = ['station', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bike_id</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>user_type</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24393</td>\n",
       "      <td>3202</td>\n",
       "      <td>2016-02-01 00:31:18</td>\n",
       "      <td>3203</td>\n",
       "      <td>2016-02-01 00:37:19</td>\n",
       "      <td>361</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1975</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24394</td>\n",
       "      <td>3195</td>\n",
       "      <td>2016-02-01 01:55:05</td>\n",
       "      <td>3194</td>\n",
       "      <td>2016-02-01 02:00:02</td>\n",
       "      <td>297</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1985</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24676</td>\n",
       "      <td>3183</td>\n",
       "      <td>2016-02-01 02:40:05</td>\n",
       "      <td>3210</td>\n",
       "      <td>2016-02-01 02:59:20</td>\n",
       "      <td>1155</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1976</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24700</td>\n",
       "      <td>3214</td>\n",
       "      <td>2016-02-01 05:11:28</td>\n",
       "      <td>3203</td>\n",
       "      <td>2016-02-01 05:40:58</td>\n",
       "      <td>1769</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1974</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24639</td>\n",
       "      <td>3203</td>\n",
       "      <td>2016-02-01 05:48:24</td>\n",
       "      <td>3214</td>\n",
       "      <td>2016-02-01 06:03:59</td>\n",
       "      <td>935</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1974</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24498</td>\n",
       "      <td>3212</td>\n",
       "      <td>2016-02-01 05:52:18</td>\n",
       "      <td>3185</td>\n",
       "      <td>2016-02-01 06:01:47</td>\n",
       "      <td>569</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1984</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24621</td>\n",
       "      <td>3214</td>\n",
       "      <td>2016-02-01 06:01:32</td>\n",
       "      <td>3186</td>\n",
       "      <td>2016-02-01 06:06:25</td>\n",
       "      <td>293</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1974</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24560</td>\n",
       "      <td>3209</td>\n",
       "      <td>2016-02-01 06:01:51</td>\n",
       "      <td>3186</td>\n",
       "      <td>2016-02-01 06:06:03</td>\n",
       "      <td>252</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1991</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24386</td>\n",
       "      <td>3209</td>\n",
       "      <td>2016-02-01 06:20:48</td>\n",
       "      <td>3186</td>\n",
       "      <td>2016-02-01 06:25:04</td>\n",
       "      <td>256</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1989</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24702</td>\n",
       "      <td>3184</td>\n",
       "      <td>2016-02-01 06:36:42</td>\n",
       "      <td>3183</td>\n",
       "      <td>2016-02-01 06:38:17</td>\n",
       "      <td>94</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1990</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24438</td>\n",
       "      <td>3214</td>\n",
       "      <td>2016-02-01 06:37:13</td>\n",
       "      <td>3183</td>\n",
       "      <td>2016-02-01 06:39:19</td>\n",
       "      <td>126</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1983</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24590</td>\n",
       "      <td>3194</td>\n",
       "      <td>2016-02-01 06:38:06</td>\n",
       "      <td>3195</td>\n",
       "      <td>2016-02-01 06:41:18</td>\n",
       "      <td>192</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1987</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24672</td>\n",
       "      <td>3214</td>\n",
       "      <td>2016-02-01 06:47:46</td>\n",
       "      <td>3183</td>\n",
       "      <td>2016-02-01 06:50:32</td>\n",
       "      <td>165</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1983</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24444</td>\n",
       "      <td>3194</td>\n",
       "      <td>2016-02-01 06:56:26</td>\n",
       "      <td>3195</td>\n",
       "      <td>2016-02-01 06:59:39</td>\n",
       "      <td>193</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1978</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24484</td>\n",
       "      <td>3207</td>\n",
       "      <td>2016-02-01 06:59:00</td>\n",
       "      <td>3195</td>\n",
       "      <td>2016-02-01 07:05:29</td>\n",
       "      <td>389</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1977</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24522</td>\n",
       "      <td>3215</td>\n",
       "      <td>2016-02-01 07:02:42</td>\n",
       "      <td>3215</td>\n",
       "      <td>2016-02-01 07:03:44</td>\n",
       "      <td>61</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1977</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24646</td>\n",
       "      <td>3192</td>\n",
       "      <td>2016-02-01 07:02:54</td>\n",
       "      <td>3211</td>\n",
       "      <td>2016-02-01 07:13:14</td>\n",
       "      <td>619</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1977</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24449</td>\n",
       "      <td>3209</td>\n",
       "      <td>2016-02-01 07:07:21</td>\n",
       "      <td>3184</td>\n",
       "      <td>2016-02-01 07:15:58</td>\n",
       "      <td>517</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1979</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24417</td>\n",
       "      <td>3213</td>\n",
       "      <td>2016-02-01 07:09:51</td>\n",
       "      <td>3186</td>\n",
       "      <td>2016-02-01 07:12:46</td>\n",
       "      <td>175</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1989</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24464</td>\n",
       "      <td>3187</td>\n",
       "      <td>2016-02-01 07:12:44</td>\n",
       "      <td>3183</td>\n",
       "      <td>2016-02-01 07:16:59</td>\n",
       "      <td>255</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1988</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bike_id  start_station_id           start_time  end_station_id            stop_time  trip_duration   user_type  birth_year gender\n",
       "0     24393              3202  2016-02-01 00:31:18            3203  2016-02-01 00:37:19            361  Subscriber        1975      M\n",
       "1     24394              3195  2016-02-01 01:55:05            3194  2016-02-01 02:00:02            297  Subscriber        1985      F\n",
       "2     24676              3183  2016-02-01 02:40:05            3210  2016-02-01 02:59:20           1155  Subscriber        1976      M\n",
       "3     24700              3214  2016-02-01 05:11:28            3203  2016-02-01 05:40:58           1769  Subscriber        1974      F\n",
       "4     24639              3203  2016-02-01 05:48:24            3214  2016-02-01 06:03:59            935  Subscriber        1974      F\n",
       "5     24498              3212  2016-02-01 05:52:18            3185  2016-02-01 06:01:47            569  Subscriber        1984      F\n",
       "6     24621              3214  2016-02-01 06:01:32            3186  2016-02-01 06:06:25            293  Subscriber        1974      M\n",
       "7     24560              3209  2016-02-01 06:01:51            3186  2016-02-01 06:06:03            252  Subscriber        1991      M\n",
       "8     24386              3209  2016-02-01 06:20:48            3186  2016-02-01 06:25:04            256  Subscriber        1989      F\n",
       "9     24702              3184  2016-02-01 06:36:42            3183  2016-02-01 06:38:17             94  Subscriber        1990      F\n",
       "10    24438              3214  2016-02-01 06:37:13            3183  2016-02-01 06:39:19            126  Subscriber        1983      M\n",
       "11    24590              3194  2016-02-01 06:38:06            3195  2016-02-01 06:41:18            192  Subscriber        1987      F\n",
       "12    24672              3214  2016-02-01 06:47:46            3183  2016-02-01 06:50:32            165  Subscriber        1983      M\n",
       "13    24444              3194  2016-02-01 06:56:26            3195  2016-02-01 06:59:39            193  Subscriber        1978      F\n",
       "14    24484              3207  2016-02-01 06:59:00            3195  2016-02-01 07:05:29            389  Subscriber        1977      M\n",
       "15    24522              3215  2016-02-01 07:02:42            3215  2016-02-01 07:03:44             61  Subscriber        1977      M\n",
       "16    24646              3192  2016-02-01 07:02:54            3211  2016-02-01 07:13:14            619  Subscriber        1977      M\n",
       "17    24449              3209  2016-02-01 07:07:21            3184  2016-02-01 07:15:58            517  Subscriber        1979      M\n",
       "18    24417              3213  2016-02-01 07:09:51            3186  2016-02-01 07:12:46            175  Subscriber        1989      M\n",
       "19    24464              3187  2016-02-01 07:12:44            3183  2016-02-01 07:16:59            255  Subscriber        1988      F"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>awnd_mph</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>snw_dpth</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>wdf2</th>\n",
       "      <th>wdf5</th>\n",
       "      <th>wsf2</th>\n",
       "      <th>wsf5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>270</td>\n",
       "      <td>280.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>35.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>260</td>\n",
       "      <td>260.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>10.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>270</td>\n",
       "      <td>250.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>17.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>330</td>\n",
       "      <td>330.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>33.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>360</td>\n",
       "      <td>350.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>31.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>230</td>\n",
       "      <td>250.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>360.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-01-09</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>15.43</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>65</td>\n",
       "      <td>39</td>\n",
       "      <td>260</td>\n",
       "      <td>270.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>42.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>16.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>270</td>\n",
       "      <td>290.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>22</td>\n",
       "      <td>270</td>\n",
       "      <td>240.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>42.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>18.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>270</td>\n",
       "      <td>260.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>44.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>250</td>\n",
       "      <td>250.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>160</td>\n",
       "      <td>160.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>11.63</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>55</td>\n",
       "      <td>42</td>\n",
       "      <td>280</td>\n",
       "      <td>310.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "      <td>320</td>\n",
       "      <td>340.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>17.22</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>290</td>\n",
       "      <td>280.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>19.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>290</td>\n",
       "      <td>280.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>300</td>\n",
       "      <td>290.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>31.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  awnd_mph  prcp  snow  snw_dpth  tavg  tmax  tmin  wdf2   wdf5  wsf2  wsf5\n",
       "0   2016-01-01     12.75  0.00   0.0       0.0    41    43    34   270  280.0  25.9  35.1\n",
       "1   2016-01-02      9.40  0.00   0.0       0.0    36    42    30   260  260.0  21.0  25.1\n",
       "2   2016-01-03     10.29  0.00   0.0       0.0    37    47    28   270  250.0  23.9  30.0\n",
       "3   2016-01-04     17.22  0.00   0.0       0.0    32    35    14   330  330.0  25.9  33.1\n",
       "4   2016-01-05      9.84  0.00   0.0       0.0    19    31    10   360  350.0  25.1  31.1\n",
       "5   2016-01-06      5.37  0.00   0.0       0.0    28    42    15   230  250.0  12.1  16.1\n",
       "6   2016-01-07      3.36  0.00   0.0       0.0    35    46    24    20  360.0   8.9  10.1\n",
       "7   2016-01-08      8.05  0.00   0.0       0.0    38    45    31    20   30.0  14.1  16.1\n",
       "8   2016-01-09      6.71  0.01   0.0       0.0    44    48    38    60   70.0  13.0  17.0\n",
       "9   2016-01-10     15.43  1.77   0.0       0.0    53    65    39   260  270.0  36.0  42.9\n",
       "10  2016-01-11     16.33  0.00   0.0       0.0    36    39    24   270  290.0  31.1  45.0\n",
       "11  2016-01-12      8.72  0.01   0.0       0.0    31    44    22   270  240.0  35.1  42.9\n",
       "12  2016-01-13     18.12  0.00   0.0       0.0    27    31    22   270  260.0  31.1  44.1\n",
       "13  2016-01-14      8.05  0.00   0.0       0.0    28    39    23   250  250.0  21.0  25.9\n",
       "14  2016-01-15      3.80  0.00   0.0       0.0    38    49    29   160  160.0  10.1  15.0\n",
       "15  2016-01-16     11.63  0.26   0.0       0.0    47    55    42   280  310.0  21.9  28.0\n",
       "16  2016-01-17      9.40  0.07   0.7       0.0    38    42    29   320  340.0  18.1  23.0\n",
       "17  2016-01-18     17.22  0.03   0.5       1.2    27    30    18   290  280.0  29.1  38.0\n",
       "18  2016-01-19     19.01  0.00   0.0       0.0    21    31    16   290  280.0  29.1  40.0\n",
       "19  2016-01-20      9.40  0.00   0.0       0.0    31    39    27   300  290.0  21.9  31.1"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.to_csv('trip_data.csv', index=False)\n",
    "weather.to_csv('weather.csv', index=False)\n",
    "stations.to_csv('stations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3.) Create a Database Schema (Lucid Chart)\n",
    "<img src='images/schema_screenshot.png' width=\"600\">\n",
    "<br>\n",
    "\n",
    "## (4.) Import Data and Create Views for Analysis (PostgreSQL)\n",
    "\n",
    "### Import Data\n",
    "First I imported the files I had cleaned with Python from my project folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- import stations.csv into the stations table\n",
    "COPY stations(\n",
    "  id,\n",
    "  name,\n",
    "  latitude,\n",
    "  longitude\n",
    ")\n",
    "FROM '/python_cleanup_export/stations.csv'\n",
    "DELIMITER ','\n",
    "CSV HEADER;\n",
    "\n",
    "-- import weather.csv into the weather table\n",
    "COPY weather(\n",
    "  date,\n",
    "  awnd_mph,\n",
    "  prcp,\n",
    "  snow,\n",
    "  snw_dpth,\n",
    "  tavg,\n",
    "  tmax,\n",
    "  tmin,\n",
    "  wdf2,\n",
    "  wdf5,\n",
    "  wsf2,\n",
    "  wsf5\n",
    ")\n",
    "FROM '/python_cleanup_export/weather.csv'\n",
    "DELIMITER ','\n",
    "CSV HEADER;\n",
    "\n",
    "-- import trip_data.csv into the trip_data table\n",
    "COPY trip_data(\n",
    "  trip_id,\n",
    "  bike_id,\n",
    "  start_station_id,\n",
    "  start_time,\n",
    "  end_station_id,\n",
    "  stop_time,\n",
    "  trip_duration,\n",
    "  user_type,\n",
    "  birth_year,\n",
    "  gender\n",
    ")\n",
    "FROM '/python_cleanup_export/trip_data.csv'\n",
    "DELIMITER ','\n",
    "CSV HEADER;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Views\n",
    "\n",
    "<details>\n",
    "  <summary>av_rides_hourly</summary>\n",
    "  <pre><code class=\"language-sql\">\n",
    "CREATE VIEW avg_rides_hourly AS (\n",
    "\n",
    "  WITH \n",
    "  hours AS (\n",
    "    SELECT DISTINCT \n",
    "      TO_CHAR(start_time, 'HH24') AS hour\n",
    "    FROM trip_data\n",
    "    ORDER BY 1\n",
    "  ),\n",
    "\n",
    "  assign_trips AS (\n",
    "    SELECT \n",
    "      TO_CHAR(t.start_time, 'MM/DD/YYYY') AS date,\n",
    "      h.hour,\n",
    "      t.trip_id\n",
    "    FROM trip_data t\n",
    "    JOIN hours h ON h.hour = TO_CHAR(t.start_time, 'HH24')\n",
    "    ORDER BY 1\n",
    "  ),\n",
    "  \n",
    "  aggr_trips AS (\n",
    "    SELECT \n",
    "      date,\n",
    "      hour,\n",
    "      COUNT(trip_id) AS count\n",
    "    FROM assign_trips\n",
    "    GROUP BY date, hour\n",
    "    ORDER BY date, hour\n",
    "  )\n",
    "  \n",
    "  SELECT DISTINCT\n",
    "    hour, \n",
    "    ROUND(AVG(count), 0) AS avg_rides\n",
    "  FROM aggr_trips\n",
    "  GROUP BY hour\n",
    "  ORDER BY hour\n",
    ");\n",
    "  </code></pre>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>daily_trips_weather</summary>\n",
    "  <pre><code class=\"language-sql\">\n",
    "CREATE VIEW daily_trips_weather AS (\n",
    "  SELECT DISTINCT\n",
    "    w.date,\n",
    "    TO_CHAR(w.date, 'Day') AS weekday,\n",
    "    COUNT(t.trip_id) OVER (\n",
    "      PARTITION BY date\n",
    "      ) AS trips,\n",
    "  \tROUND(AVG(t.trip_duration) OVER (\n",
    "      PARTITION BY date\n",
    "    \t),2) AS avg_trip_duration,\n",
    "    w.awnd_mph,\n",
    "    w.prcp,\n",
    "    w.snow,\n",
    "    w.snw_dpth,\n",
    "    w.tavg,\n",
    "    w.tmin,\n",
    "    w.tmax,\n",
    "    w.wdf2,\n",
    "    w.wdf5,\n",
    "    w.wsf2,\n",
    "    w.wsf5\n",
    "  FROM trip_data t\n",
    "  JOIN weather w ON DATE(w.date) = DATE(t.start_time)\n",
    "  ORDER BY 1\n",
    ");\n",
    "  </code></pre>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>travel_directions</summary>\n",
    "  <pre><code class=\"language-sql\">\n",
    "CREATE VIEW travel_directions AS (\n",
    "\n",
    "WITH coords AS (\n",
    "    SELECT \n",
    "        t.trip_id,\n",
    "        d.latitude AS lat1, \n",
    "        d.longitude AS lon1,\n",
    "        a.latitude AS lat2,\n",
    "        a.longitude AS lon2\n",
    "    FROM trip_data t\n",
    "    JOIN stations d ON t.start_station_id = d.id\n",
    "    JOIN stations a ON t.end_station_id = a.id\n",
    "),\n",
    "\n",
    "directions AS (\n",
    "  SELECT \n",
    "      trip_id,\n",
    "      DEGREES(\n",
    "          ATAN2(\n",
    "              SIN(RADIANS(lon2 - lon1)) * COS(RADIANS(lat2)),\n",
    "              COS(RADIANS(lat1)) * SIN(RADIANS(lat2)) - \n",
    "              SIN(RADIANS(lat1)) * COS(RADIANS(lat2)) * COS(RADIANS(lon2 - lon1))\n",
    "          )\n",
    "      ) AS bearing_degrees\n",
    "  FROM coords\n",
    ")\n",
    "\n",
    "SELECT\n",
    "\ttrip_id,\n",
    "  bearing_degrees,\n",
    "\tCASE\n",
    "    WHEN bearing_degrees >= 337.5 OR bearing_degrees < 22.5 THEN 'N'\n",
    "    WHEN bearing_degrees >= 22.5 AND bearing_degrees < 67.5 THEN 'NE'\n",
    "    WHEN bearing_degrees >= 67.5 AND bearing_degrees < 112.5 THEN 'E'\n",
    "    WHEN bearing_degrees >= 112.5 AND bearing_degrees < 157.5 THEN 'SE'\n",
    "    WHEN bearing_degrees >= 157.5 AND bearing_degrees < 202.5 THEN 'S'\n",
    "    WHEN bearing_degrees >= 202.5 AND bearing_degrees < 247.5 THEN 'SW'\n",
    "    WHEN bearing_degrees >= 247.5 AND bearing_degrees < 292.5 THEN 'W'\n",
    "    WHEN bearing_degrees >= 292.5 AND bearing_degrees < 337.5 THEN 'NW'\n",
    "  END AS direction\n",
    "FROM directions\n",
    "  \n",
    ");\n",
    "\n",
    "  </code></pre>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>travel_vs_wind</summary>\n",
    "  <pre><code class=\"language-sql\">\n",
    "CREATE VIEW travel_vs_wind AS (\n",
    "  \n",
    "WITH cte AS (\n",
    "  SELECT \n",
    "    w.date,\n",
    "    d.trip_id,\n",
    "    concat(s.name, ' to ', e.name) AS trip,\n",
    "    t.trip_duration,\n",
    "    d.direction as trip_direction,\n",
    "    w.wdf2,\n",
    "    w.wsf2,\n",
    "    CASE\n",
    "      WHEN w.wdf2 >= 337.5 OR w.wdf2 < 22.5 THEN 'N'\n",
    "      WHEN w.wdf2 >= 22.5 AND w.wdf2 < 67.5 THEN 'NE'\n",
    "      WHEN w.wdf2 >= 67.5 AND w.wdf2 < 112.5 THEN 'E'\n",
    "      WHEN w.wdf2 >= 112.5 AND w.wdf2 < 157.5 THEN 'SE'\n",
    "      WHEN w.wdf2 >= 157.5 AND w.wdf2 < 202.5 THEN 'S'\n",
    "      WHEN w.wdf2 >= 202.5 AND w.wdf2 < 247.5 THEN 'SW'\n",
    "      WHEN w.wdf2 >= 247.5 AND w.wdf2 < 292.5 THEN 'W'\n",
    "      WHEN w.wdf2 >= 292.5 AND w.wdf2 < 337.5 THEN 'NW'\n",
    "    END AS wdf2_direction,\n",
    "    w.wdf5,\n",
    "    w.wsf5,\n",
    "    CASE\n",
    "      WHEN w.wdf5 >= 337.5 OR w.wdf5 < 22.5 THEN 'N'\n",
    "      WHEN w.wdf5 >= 22.5 AND w.wdf5 < 67.5 THEN 'NE'\n",
    "      WHEN w.wdf5 >= 67.5 AND w.wdf5 < 112.5 THEN 'E'\n",
    "      WHEN w.wdf5 >= 112.5 AND w.wdf5 < 157.5 THEN 'SE'\n",
    "      WHEN w.wdf5 >= 157.5 AND w.wdf5 < 202.5 THEN 'S'\n",
    "      WHEN w.wdf5 >= 202.5 AND w.wdf5 < 247.5 THEN 'SW'\n",
    "      WHEN w.wdf5 >= 247.5 AND w.wdf5 < 292.5 THEN 'W'\n",
    "      WHEN w.wdf5 >= 292.5 AND w.wdf5 < 337.5 THEN 'NW'\n",
    "    END AS wdf5_direction\n",
    "  FROM travel_directions d\n",
    "  JOIN trip_data t ON t.trip_id = d.trip_id\n",
    "  JOIN weather w ON DATE(w.date) = DATE(t.start_time)\n",
    "  JOIN stations s ON t.start_station_id = s.id\n",
    "  JOIN stations e ON t.end_station_id = e.id\n",
    "  )\n",
    "\n",
    "SELECT\n",
    "  date,\n",
    "  trip_id,\n",
    "  trip,\n",
    "  trip_duration,\n",
    "  trip_direction,\n",
    "  wdf2,\n",
    "  wsf2,\n",
    "  wdf2_direction,\n",
    "  wdf5,\n",
    "  wsf5,\n",
    "  wdf5_direction,\n",
    "  CASE\n",
    "  \tWHEN\n",
    "  \t\t(trip_direction = 'N' AND (wdf2_direction = 'S' OR wdf5_direction = 'S'))\n",
    "  OR \t(trip_direction = 'NW' AND (wdf2_direction = 'SE' OR wdf5_direction = 'SE'))\n",
    "  OR \t(trip_direction = 'W' AND (wdf2_direction = 'E' OR wdf5_direction = 'E'))\n",
    "  OR \t(trip_direction = 'SW' AND (wdf2_direction = 'NE' OR wdf5_direction = 'NE'))\n",
    "  OR \t(trip_direction = 'S' AND (wdf2_direction = 'N' OR wdf5_direction = 'N'))\n",
    "  OR \t(trip_direction = 'SE' AND (wdf2_direction = 'NW' OR wdf5_direction = 'NW'))\n",
    "  OR \t(trip_direction = 'E' AND (wdf2_direction = 'W' OR wdf5_direction = 'W'))\n",
    "  OR \t(trip_direction = 'NE' AND (wdf2_direction = 'SW' OR wdf5_direction = 'SW'))\n",
    "  THEN 1\n",
    "  ELSE 0\n",
    "  END AS against_wind\n",
    "FROM cte\n",
    "WHERE trip_duration <= 28800\n",
    "ORDER BY date\n",
    ");\n",
    "  </code></pre>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>weather_and_trips_duration</summary>\n",
    "  <pre><code class=\"language-sql\">\n",
    "CREATE VIEW weather_trips_and_duration AS (\n",
    "WITH cte AS (\n",
    "  SELECT DISTINCT\n",
    "    w.date,\n",
    "    t.trip_id,\n",
    "    t.trip_duration,\n",
    "    CASE\n",
    "      WHEN w.prcp > 0\n",
    "      THEN 1\n",
    "      ELSE 0\n",
    "    END AS is_rain,\n",
    "    CASE\n",
    "      WHEN (w.snow > 0 OR w.snw_dpth > 2)\n",
    "      THEN 1\n",
    "      ELSE 0\n",
    "    END AS is_snow,\n",
    "    CASE\n",
    "      WHEN (w.wsf2 > 20 OR w.wsf5 > 20)\n",
    "      THEN 1\n",
    "      ELSE 0\n",
    "    END AS is_windy\n",
    "  FROM trip_data t\n",
    "  JOIN weather w ON DATE(w.date) = DATE(t.start_time)\n",
    "  ORDER BY 1\n",
    "  ),\n",
    "\n",
    "clear AS (\n",
    "  SELECT\n",
    "  \tdate,\n",
    "  \tCOUNT(trip_id) AS ct_trips,\n",
    "  \tROUND(AVG(trip_duration),2) AS avg_duration\n",
    " \tFROM cte\n",
    "  WHERE (is_rain = 0 AND is_snow = 0 AND is_windy = 0)\n",
    "  GROUP BY date\n",
    "  ORDER BY date\n",
    "\t),\n",
    "  \n",
    "rain AS (\n",
    "  SELECT\n",
    "  \tdate,\n",
    "  \tCOUNT(trip_id) AS ct_trips,\n",
    "  \tROUND(AVG(trip_duration),2) AS avg_duration\n",
    " \tFROM cte\n",
    "  WHERE is_rain = 1\n",
    "  GROUP BY date\n",
    "  ORDER BY date\n",
    "\t),\n",
    "\n",
    "snow AS (\n",
    "  SELECT\n",
    "  \tdate,\n",
    "  \tCOUNT(trip_id) AS ct_trips,\n",
    "  \tROUND(AVG(trip_duration),2) AS avg_duration\n",
    " \tFROM cte\n",
    "  WHERE is_snow = 1\n",
    "  GROUP BY date\n",
    "  ORDER BY date\n",
    "\t),\n",
    "\n",
    "windy AS (\n",
    "  SELECT\n",
    "  \tdate,\n",
    "  \tCOUNT(trip_id) AS ct_trips,\n",
    "  \tROUND(AVG(trip_duration),2) AS avg_duration\n",
    " \tFROM cte\n",
    "  WHERE is_windy = 1\n",
    "  GROUP BY date\n",
    "  ORDER BY date\n",
    "\t)\n",
    "\n",
    "SELECT\n",
    "\tROUND(AVG(clear.ct_trips),2) AS avg_clear_trips,\n",
    "  ROUND(AVG(clear.avg_duration),2) AS avg_clear_duration,\n",
    "  ROUND(AVG(rain.ct_trips),2) AS avg_rain_trips,\n",
    "  ROUND(AVG(rain.avg_duration),2) AS avg_rain_duration,\n",
    "  ROUND(AVG(snow.ct_trips),2) AS avg_snow_trips,\n",
    "  ROUND(AVG(snow.avg_duration),2) AS avg_snow_duration,\n",
    "  ROUND(AVG(windy.ct_trips),2) AS avg_windy_trips,\n",
    "  ROUND(AVG(windy.avg_duration),2) AS avg_windy_duration\n",
    "FROM clear, rain, snow, windy\n",
    "\n",
    ");\n",
    "  </code></pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Views as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "COPY (SELECT * FROM avg_rides_hourly) TO '/Users/nate/Data_Projects/Bike Rental Portfolio Project/avg_rides_hourly.csv' DELIMITER ',' CSV HEADER;\n",
    "COPY (SELECT * FROM daily_trips_weather) TO '/Users/nate/Data_Projects/Bike Rental Portfolio Project/daily_trips_weather.csv' DELIMITER ',' CSV HEADER;\n",
    "COPY (SELECT * FROM travel_directions) TO '/Users/nate/Data_Projects/Bike Rental Portfolio Project/travel_directions.csv' DELIMITER ',' CSV HEADER;\n",
    "COPY (SELECT * FROM travel_vs_wind) TO '/Users/nate/Data_Projects/Bike Rental Portfolio Project/travel_vs_wind.csv' DELIMITER ',' CSV HEADER;\n",
    "COPY (SELECT * FROM weather_trips_and_duration) TO '/Users/nate/Data_Projects/Bike Rental Portfolio Project/weather_trips_and_duration.csv' DELIMITER ',' CSV HEADER;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Visualizations (Tableau)\n",
    "I wanted to create some quick visualizations just to put the data to use so I put together two simple visuals with Tableau:\n",
    "\n",
    "Using a top 10 filter and counting the records we can see what trips were most popular in 2016.\n",
    "<br>\n",
    "<img src='images/top_10_trips_viz.png' width=\"400\">\n",
    "<br>\n",
    "\n",
    "My next idea was to use a visual to see if there was a significant affect on ride duration if riders were traveling against strong oncoming wind. Unfortunately, it didn’t seem like there was any affect. In fact, the average trip duration was longer when there was no oncoming wind.\n",
    "<br>\n",
    "<img src='images/riding_against_wind_viz.png' width=\"400\">\n",
    "<br>\n",
    "\n",
    "Lastly, I used the weather_trips_and_duration view to visualize the effect that the weather has on the number of rides daily and their average duration.\n",
    "From the graph you can see that customers are far less likely to ride in the rain or snow than they are on clear or windy days. Unlike the graph above, it does seem here that wind has a large effect on ride duration, regardless of wind being head-on or not.\n",
    "<br>\n",
    "<img src='images/weather_vs_trips_viz.png' width=\"400\">\n",
    "<br>\n",
    "\n",
    "This CitiBike project analyzed a year's worth of bike rental data to understand the impact of weather on riding patterns. Using Python for data processing and PostgreSQL for database management, I conducted a comprehensive analysis of the dataset. Key findings include identifying the most popular bike trips in 2016 and, the effect of headwinds on trip duration, and the overall effect on weather on daily ride activity. This was a great exercise to practice my skills in preparing data for analysis, and I’m looking forward to what else Codecademy has to offer in its Data Engineering Career Path."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
